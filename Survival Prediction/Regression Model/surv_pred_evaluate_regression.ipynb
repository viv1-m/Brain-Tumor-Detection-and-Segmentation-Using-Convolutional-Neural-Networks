{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shalabh147/Brain-Tumor-Segmentation-and-Survival-Prediction-using-Deep-Neural-Networks/blob/master/surv_pred_evaluate_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "6FmM1Cw1_ivU",
    "outputId": "a2e113bb-855d-41b0-8d05-ef3d68bbb258"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "# import keras\n",
    "# from ensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,Maximum,Flatten\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose,UpSampling2D\n",
    "# from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose,UpSampling2D\n",
    "# from tensorflow.keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose,UpSampling2D\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D,MaxPooling3D,AveragePooling2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import class_weight\n",
    "from keras.models import Sequential\n",
    "import nibabel as nib\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "path1 = '/home/vivek/Desktop/BTP_2020/Segmentation/Brain-Tumor-Segmentation-and-Survival-Prediction-using-Deep-Neural-Networks/survival_data.csv'\n",
    "#print(os.listdir(path))\n",
    "# Brats18_CBICA_ANP_1\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "swpJZ3YZ_iva",
    "outputId": "90768946-1032-42fb-e88b-78f927de4e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are Brats17ID, Age, Survival\n",
      "['Brats17_TCIA_167_1', '74.907', '153']\n",
      "['Brats17_TCIA_242_1', '66.479', '147']\n",
      "['Brats17_TCIA_319_1', '64.860', '254']\n",
      "['Brats17_TCIA_469_1', '63.899', '519']\n",
      "['Brats17_TCIA_218_1', '57.345', '346']\n",
      "['Brats17_TCIA_406_1', '78.745', '82']\n",
      "['Brats17_TCIA_280_1', '57.362', '508']\n",
      "['Brats17_TCIA_105_1', '66.627', '77']\n",
      "['Brats17_TCIA_278_1', '50.501', '1458']\n",
      "['Brats17_TCIA_247_1', '76.699', '244']\n",
      "['Brats17_TCIA_372_1', '74.521', '213']\n",
      "['Brats17_TCIA_165_1', '51.756', '5']\n",
      "['Brats17_TCIA_409_1', '69.266', '99']\n",
      "['Brats17_TCIA_184_1', '61.167', '434']\n",
      "['Brats17_TCIA_277_1', '70.367', '232']\n",
      "['Brats17_TCIA_478_1', '59.255', '30']\n",
      "['Brats17_TCIA_437_1', '46.953', '333']\n",
      "['Brats17_TCIA_361_1', '75.973', '476']\n",
      "['Brats17_TCIA_192_1', '75.962', '121']\n",
      "['Brats17_TCIA_479_1', '56.400', '372']\n",
      "['Brats17_TCIA_111_1', '75.263', '626']\n",
      "['Brats17_TCIA_343_1', '52.679', '296']\n",
      "['Brats17_TCIA_149_1', '36.852', '448']\n",
      "['Brats17_TCIA_474_1', '61.408', '635']\n",
      "['Brats17_TCIA_419_1', '70.592', '327']\n",
      "['Brats17_TCIA_199_1', '48.825', '1282']\n",
      "['Brats17_TCIA_133_1', '63.762', '382']\n",
      "['Brats17_TCIA_296_1', '60.427', '22']\n",
      "['Brats17_TCIA_257_1', '69.326', '425']\n",
      "['Brats17_TCIA_498_1', '59.282', '467']\n",
      "['Brats17_TCIA_138_1', '71.874', '82']\n",
      "['Brats17_TCIA_338_1', '76.425', '468']\n",
      "['Brats17_TCIA_265_1', '59.584', '103']\n",
      "['Brats17_TCIA_375_1', '60.000', '946']\n",
      "['Brats17_TCIA_121_1', '30.408', '747']\n",
      "['Brats17_TCIA_274_1', '54.967', '357']\n",
      "['Brats17_TCIA_473_1', '61.022', '175']\n",
      "['Brats17_TCIA_322_1', '57.362', '621']\n",
      "['Brats17_TCIA_179_1', '46.677', '405']\n",
      "['Brats17_TCIA_368_1', '62.562', '317']\n",
      "['Brats17_TCIA_135_1', '69.364', '828']\n",
      "['Brats17_TCIA_471_1', '76.614', '111']\n",
      "['Brats17_TCIA_394_1', '64.247', '616']\n",
      "['Brats17_TCIA_300_1', '64.378', '127']\n",
      "['Brats17_TCIA_151_1', '47.973', '1731']\n",
      "['Brats17_TCIA_118_1', '47.321', '104']\n",
      "['Brats17_TCIA_226_1', '73.578', '329']\n",
      "['Brats17_TCIA_455_1', '54.844', '424']\n",
      "['Brats17_TCIA_283_1', '74.836', '262']\n",
      "['Brats17_TCIA_430_1', '53.866', '71']\n",
      "['Brats17_TCIA_321_1', '81.211', '67']\n",
      "['Brats17_TCIA_314_1', '40.353', '362']\n",
      "['Brats17_TCIA_290_1', '43.112', '737']\n",
      "['Brats17_TCIA_377_1', '63.762', '812']\n",
      "['Brats17_TCIA_198_1', '54.279', '394']\n",
      "['Brats17_TCIA_331_1', '84.844', '187']\n",
      "['Brats17_TCIA_491_1', '81.112', '82']\n",
      "['Brats17_TCIA_150_1', '51.115', '1489']\n",
      "['Brats17_TCIA_335_1', '54.474', '355']\n",
      "['Brats17_TCIA_411_1', '42.904', '822']\n",
      "['Brats17_TCIA_203_1', '45.926', '268']\n",
      "['Brats17_TCIA_231_1', '63.805', '1561']\n",
      "['Brats17_TCIA_390_1', '63.575', '634']\n",
      "['Brats17_TCIA_235_1', '57.973', '804']\n",
      "['Brats17_TCIA_499_1', '50.082', '600']\n",
      "['Brats17_TCIA_412_1', '68.759', '291']\n",
      "['Brats17_TCIA_448_1', '44.449', '199']\n",
      "['Brats17_TCIA_401_1', '78.792', '448']\n",
      "['Brats17_TCIA_147_1', '61.416', '209']\n",
      "['Brats17_TCIA_378_1', '74.145', '110']\n",
      "['Brats17_TCIA_201_1', '60.729', '430']\n",
      "['Brats17_TCIA_429_1', '54.986', '86']\n",
      "['Brats17_TCIA_186_1', '33.888', '370']\n",
      "['Brats17_TCIA_460_1', '18.975', '630']\n",
      "['Brats17_TCIA_190_1', '61.526', '322']\n",
      "['Brats17_TCIA_425_1', '56.208', '558']\n",
      "['Brats17_2013_11_1', '29.120', '150']\n",
      "['Brats17_2013_27_1', '68.020', '120']\n",
      "['Brats17_CBICA_BHM_1', '62.030', '436']\n",
      "['Brats17_CBICA_BHB_1', '55.595', '510']\n",
      "['Brats17_CBICA_AZH_1', '54.915', '401']\n",
      "['Brats17_CBICA_AZD_1', '46.258', '448']\n",
      "['Brats17_CBICA_AYW_1', '49.874', '734']\n",
      "['Brats17_CBICA_AYU_1', '63.781', '58']\n",
      "['Brats17_CBICA_AYI_1', '65.921', '387']\n",
      "['Brats17_CBICA_AYA_1', '74.836', '50']\n",
      "['Brats17_CBICA_AXW_1', '79.211', '191']\n",
      "['Brats17_CBICA_AXQ_1', '66.282', '114']\n",
      "['Brats17_CBICA_AXO_1', '56.301', '394']\n",
      "['Brats17_CBICA_AXN_1', '85.762', '345']\n",
      "['Brats17_CBICA_AXM_1', '66.934', '438']\n",
      "['Brats17_CBICA_AXL_1', '74.630', '168']\n",
      "['Brats17_CBICA_AXJ_1', '27.811', '1767']\n",
      "['Brats17_CBICA_AWI_1', '46.551', '375']\n",
      "['Brats17_CBICA_AWH_1', '52.764', '139']\n",
      "['Brats17_CBICA_AWG_1', '55.532', '180']\n",
      "['Brats17_CBICA_AVV_1', '72.293', '387']\n",
      "['Brats17_CBICA_AVJ_1', '45.244', '614']\n",
      "['Brats17_CBICA_AVG_1', '63.359', '579']\n",
      "['Brats17_CBICA_AUR_1', '70.252', '12']\n",
      "['Brats17_CBICA_AUQ_1', '60.816', '1337']\n",
      "['Brats17_CBICA_AUN_1', '68.504', '376']\n",
      "['Brats17_CBICA_ATX_1', '36.784', '1592']\n",
      "['Brats17_CBICA_ATV_1', '62.159', '453']\n",
      "['Brats17_CBICA_ATP_1', '51.589', '385']\n",
      "['Brats17_CBICA_ATF_1', '68.726', '152']\n",
      "['Brats17_CBICA_ATD_1', '69.178', '355']\n",
      "['Brats17_CBICA_ATB_1', '71.126', '208']\n",
      "['Brats17_CBICA_ASY_1', '66.510', '610']\n",
      "['Brats17_CBICA_ASW_1', '68.359', '239']\n",
      "['Brats17_CBICA_ASV_1', '54.751', '597']\n",
      "['Brats17_CBICA_ASU_1', '81.285', '85']\n",
      "['Brats17_CBICA_ASO_1', '52.348', '265']\n",
      "['Brats17_CBICA_ASN_1', '39.488', '407']\n",
      "['Brats17_CBICA_ASK_1', '77.337', '522']\n",
      "['Brats17_CBICA_ASH_1', '46.570', '660']\n",
      "['Brats17_CBICA_ASG_1', '57.710', '208']\n",
      "['Brats17_CBICA_ASE_1', '46.814', '318']\n",
      "['Brats17_CBICA_ASA_1', '63.764', '210']\n",
      "['Brats17_CBICA_ARZ_1', '54.825', '871']\n",
      "['Brats17_CBICA_ARW_1', '44.416', '495']\n",
      "['Brats17_CBICA_ARF_1', '75.312', '726']\n",
      "['Brats17_CBICA_AQZ_1', '63.345', '286']\n",
      "['Brats17_CBICA_AQY_1', '57.718', '229']\n",
      "['Brats17_CBICA_AQV_1', '53.362', '84']\n",
      "['Brats17_CBICA_AQU_1', '72.879', '30']\n",
      "['Brats17_CBICA_AQT_1', '75.978', '172']\n",
      "['Brats17_CBICA_AQR_1', '71.370', '89']\n",
      "['Brats17_CBICA_AQQ_1', '69.992', '33']\n",
      "['Brats17_CBICA_AQP_1', '46.452', '1283']\n",
      "['Brats17_CBICA_AQO_1', '67.860', '473']\n",
      "['Brats17_CBICA_AQN_1', '63.192', '488']\n",
      "['Brats17_CBICA_AQJ_1', '66.074', '170']\n",
      "['Brats17_CBICA_AQG_1', '53.605', '466']\n",
      "['Brats17_CBICA_AQD_1', '73.036', '32']\n",
      "['Brats17_CBICA_AQA_1', '76.367', '106']\n",
      "['Brats17_CBICA_APZ_1', '60.063', '336']\n",
      "['Brats17_CBICA_APY_1', '45.548', '203']\n",
      "['Brats17_CBICA_APR_1', '62.704', '23']\n",
      "['Brats17_CBICA_AOZ_1', '46.666', '331']\n",
      "['Brats17_CBICA_AOP_1', '67.833', '332']\n",
      "['Brats17_CBICA_AOO_1', '44.162', '350']\n",
      "['Brats17_CBICA_AOH_1', '56.921', '576']\n",
      "['Brats17_CBICA_AOD_1', '60.581', '55']\n",
      "['Brats17_CBICA_ANZ_1', '68.049', '287']\n",
      "['Brats17_CBICA_ANP_1', '61.605', '486']\n",
      "['Brats17_CBICA_ANI_1', '58.258', '439']\n",
      "['Brats17_CBICA_ANG_1', '55.759', '368']\n",
      "['Brats17_CBICA_AMH_1', '62.614', '169']\n",
      "['Brats17_CBICA_AME_1', '51.734', '359']\n",
      "['Brats17_CBICA_ALX_1', '59.693', '698']\n",
      "['Brats17_CBICA_ALU_1', '65.899', '495']\n",
      "['Brats17_CBICA_ALN_1', '60.942', '421']\n",
      "['Brats17_CBICA_ABY_1', '48.367', '515']\n",
      "['Brats17_CBICA_ABO_1', '56.419', '1155']\n",
      "['Brats17_CBICA_ABN_1', '68.285', '1278']\n",
      "['Brats17_CBICA_ABM_1', '69.912', '503']\n",
      "['Brats17_CBICA_ABE_1', '67.126', '269']\n",
      "['Brats17_CBICA_ABB_1', '68.493', '465']\n",
      "['Brats17_CBICA_AAP_1', '39.068', '788']\n",
      "['Brats17_CBICA_AAL_1', '54.301', '464']\n",
      "['Brats17_CBICA_AAG_1', '52.263', '616']\n",
      "['Brats17_CBICA_AAB_1', '60.463', '289']\n",
      "Processed 164 lines.\n",
      "55 64 44\n",
      "1767\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "#import pickle\n",
    "\n",
    "#from joblib import dump\n",
    "\n",
    "age_dict = {}\n",
    "days_dict = {}\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    axis = (0,1,2)\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "with open(path1, mode='r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file,delimiter = ',')\n",
    "    line_count = 0\n",
    "    a = 0\n",
    "    b = 0\n",
    "    max_days = 0\n",
    "    c = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "            line_count += 1\n",
    "        else:\n",
    "            print(row)\n",
    "            key = row[0]\n",
    "            age = row[1]\n",
    "            days = row[2]\n",
    "            age_dict[key] = float(age)\n",
    "            days_dict[key] = int(days)\n",
    "            max_days = max(max_days,int(days))\n",
    "            if int(days) < 250:\n",
    "                a += 1\n",
    "            elif (int(days) >= 250 and int(days) <= 500):\n",
    "                b += 1\n",
    "            else:\n",
    "                c += 1\n",
    "            line_count+=1\n",
    "\n",
    "    print(f'Processed {line_count} lines.')\n",
    "    #age_m = np.zeros((1,1))\n",
    "    print(a,b,c)\n",
    "    print(max_days)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x1zuUuXE_ive"
   },
   "outputs": [],
   "source": [
    "surv_model = load_model('../input/heheregression/surv_predreg.h5')\n",
    "seg_model = load_model('../input/surv-pred-models/2d_4class_axis3.h5' , custom_objects = {'dice_coef_loss' :  dice_coef_loss , 'dice_coef' : dice_coef})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7I1StLN_ivh"
   },
   "outputs": [],
   "source": [
    "path = '/home/vivek/Desktop/BTP_2020/Segmentation/dataset/MICCAI_BraTS_2018_Data_Training/HGG'\n",
    "all_images = os.listdir(path)\n",
    "#print(len(all_images))\n",
    "all_images.sort()\n",
    "\n",
    "def standardize(image):\n",
    "\n",
    "  standardized_image = np.zeros(image.shape)\n",
    "\n",
    "  #\n",
    " \n",
    "      # iterate over the `z` dimension\n",
    "  for z in range(image.shape[2]):\n",
    "      # get a slice of the image\n",
    "      # at channel c and z-th dimension `z`\n",
    "      image_slice = image[:,:,z]\n",
    "\n",
    "      # subtract the mean from image_slice\n",
    "      centered = image_slice - np.mean(image_slice)\n",
    "     \n",
    "      # divide by the standard deviation (only if it is different from zero)\n",
    "      if(np.std(centered)!=0):\n",
    "          centered = centered/np.std(centered)\n",
    "\n",
    "      # update  the slice of standardized image\n",
    "      # with the scaled centered and scaled image\n",
    "      standardized_image[:, :, z] = centered\n",
    "\n",
    "  ### END CODE HERE ###\n",
    "\n",
    "  return standardized_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H2slVvwn_ivk",
    "outputId": "4a28f289-9e08-472b-a061-625894560e10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29, 240, 240, 4)\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2107 - mean_squared_error: 0.2107\n",
      "[[  22.]\n",
      " [ 468.]\n",
      " [ 946.]\n",
      " [ 327.]\n",
      " [ 635.]\n",
      " [ 467.]\n",
      " [ 626.]\n",
      " [ 448.]\n",
      " [ 121.]\n",
      " [ 296.]\n",
      " [ 476.]\n",
      " [ 333.]\n",
      " [ 372.]\n",
      " [ 232.]\n",
      " [  30.]\n",
      " [   5.]\n",
      " [ 434.]\n",
      " [ 244.]\n",
      " [ 213.]\n",
      " [  99.]\n",
      " [  77.]\n",
      " [ 153.]\n",
      " [ 346.]\n",
      " [ 147.]\n",
      " [1458.]\n",
      " [ 508.]\n",
      " [ 254.]\n",
      " [  82.]\n",
      " [ 519.]]\n",
      "[[ 813.6175 ]\n",
      " [ 250.73135]\n",
      " [ 958.6666 ]\n",
      " [ 972.3248 ]\n",
      " [1279.6447 ]\n",
      " [1312.3201 ]\n",
      " [1098.0134 ]\n",
      " [1498.8267 ]\n",
      " [ 772.1209 ]\n",
      " [1388.0165 ]\n",
      " [1032.0972 ]\n",
      " [1105.5706 ]\n",
      " [1393.6545 ]\n",
      " [1303.1383 ]\n",
      " [1195.2557 ]\n",
      " [1296.0067 ]\n",
      " [1485.108  ]\n",
      " [ 379.31024]\n",
      " [1175.849  ]\n",
      " [ 463.3608 ]\n",
      " [ 896.01764]\n",
      " [ 840.3019 ]\n",
      " [1275.8517 ]\n",
      " [ 980.8081 ]\n",
      " [1321.864  ]\n",
      " [1606.7034 ]\n",
      " [ 706.48157]\n",
      " [1166.2017 ]\n",
      " [1070.7634 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" \\nplt.plot(history.history['loss'])\\nplt.title('Model_loss vs epochs')\\nplt.ylabel('Loss')\\nplt.xlabel('epochs')\\ns = '../working/epochwise_loss'\\nplt.savefig(s)\\nplt.show()\\nplt.close()\\n\\nplt.plot(history.history['accuracy'])\\nplt.title('Model_Accuracy vs epochs')\\nplt.ylabel('Accuracy')\\nplt.xlabel('epochs')\\ns = '../working/epochwise_accuracy'\\nplt.savefig(s)\\nplt.show()\\nplt.close()\\n\\n\\nplt.plot(accu_hist)\\nplt.title('model accuracy')\\nplt.ylabel('accuracy')\\nplt.xlabel('epoch')\\ns = '../working/accuracy_plot_' + str(epochs)\\nplt.savefig(s)\\nplt.show()\\nplt.close()\\n\\nplt.plot(loss_hist)\\nplt.title('model loss')\\nplt.ylabel('loss')\\nplt.xlabel('epoch')\\ns = '../working/loss_plot_' + str(epochs)\\nplt.savefig(s)\\nplt.show()\\nplt.close()\\n\\nmodel.save('../working/2d_4class_axis1.h5')\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loss_hist = []\n",
    "#accu_hist = []\n",
    "#epoch_wise_loss = []\n",
    "#epoch_wise_accu = []\n",
    "#for epochs in range(45):\n",
    "epoch_loss = 0\n",
    "epoch_accu = 0\n",
    "input_to_model = np.zeros((29,240,240,5))\n",
    "age = np.zeros((29,1))\n",
    "ground_truth = np.zeros((29,1))\n",
    "cnt = 0\n",
    "for image_num in range(170,210):\n",
    "    #print(epochs)\n",
    "    #print(\"image_num \",image_num)\n",
    "    #print(\"cnt\" ,cnt)\n",
    "    data = np.zeros((240,240,155,4))\n",
    "    image_data2=np.zeros((240,240,155))\n",
    "\n",
    "    # data preprocessing starts here\n",
    "\n",
    "    x = all_images[image_num]\n",
    "    \n",
    "    if x in days_dict:\n",
    "        #print(cnt)\n",
    "        #print(x)\n",
    "        folder_path = path + '/' + x;\n",
    "        modalities = os.listdir(folder_path)\n",
    "        modalities.sort()\n",
    "        #data = []\n",
    "        w = 0\n",
    "        for j in range(len(modalities)):\n",
    "          #print(modalities[j])\n",
    "\n",
    "          image_path = folder_path + '/' + modalities[j]\n",
    "          if not(image_path.find('seg.nii') == -1):\n",
    "            img = nib.load(image_path);\n",
    "            image_data2 = img.get_data()\n",
    "            image_data2 = np.asarray(image_data2)\n",
    "            #print(\"Entered ground truth\")\n",
    "          else:\n",
    "            img = nib.load(image_path);\n",
    "            image_data = img.get_data()\n",
    "            image_data = np.asarray(image_data)\n",
    "            image_data = standardize(image_data)\n",
    "            data[:,:,:,w] = image_data\n",
    "            #print(\"Entered modality\")\n",
    "            w = w+1\n",
    "\n",
    "        #print(data.shape)\n",
    "        #print(image_data2.shape)\n",
    "        image_data2[image_data2 == 4] = 3\n",
    "\n",
    "        input_to_model[cnt,:,:,:4] = data[:,:,75,:]\n",
    "        #input_to_model[cnt,:,:,4] = image_data2[:,:,75]\n",
    "        #age = np.zeros((1,1))\n",
    "        age[cnt,0] = float(age_dict[x])\n",
    "        days = int(days_dict[x])\n",
    "        \n",
    "\n",
    "        #ground_truth = np.zeros((1,3))\n",
    "        #print(age[cnt,0])\n",
    "        '''\n",
    "        if int(days) < 300:\n",
    "            ground_truth[cnt,0] = 1\n",
    "        elif (int(days) >= 300 and int(days) <= 450):\n",
    "            ground_truth[cnt,1] = 1\n",
    "        else:\n",
    "            ground_truth[cnt,2] = 1 \n",
    "        '''\n",
    "        ground_truth[cnt,0] = int(days)/max_days\n",
    "        #print(ground_truth[cnt])\n",
    "        cnt += 1\n",
    "        \n",
    "\n",
    "    #y_to = keras.utils.to_categorical(y_to,num_classes=4)\n",
    "to_segment = input_to_model[:,:,:,:4]\n",
    "after_segment = seg_model.predict(x = to_segment)\n",
    "print(after_segment.shape)\n",
    "after_segment = np.argmax(after_segment, axis = -1)\n",
    "input_to_model[:,:,:,4] = after_segment\n",
    "#print(ground_truth.shape)\n",
    "#print(age.shape)\n",
    "#print(input_to_model.shape)\n",
    "scores = surv_model.evaluate(x = [input_to_model,age], y = ground_truth)\n",
    "pred = surv_model.predict(x=[input_to_model,age])\n",
    "print(ground_truth*max_days)\n",
    "print(pred*max_days)\n",
    "#pred = np.argmax(pred,axis = -1)\n",
    "#ground_truth = np.argmax(ground_truth,axis = -1)\n",
    "#print(pred == ground_truth)\n",
    "#print(history.history['loss'])\n",
    "#epoch_loss += history.history['loss'][0]\n",
    "#epoch_accu += history.history['accuracy'][0]\n",
    "\n",
    "#loss_hist.append(history.history['loss'])\n",
    "#accu_hist.append(history.history['accuracy'])\n",
    "\n",
    "#model.save('../working/surv_pred3.h5')\n",
    "#epoch_loss = epoch_loss/180\n",
    "#epoch_accu = epoch_accu/180\n",
    "\n",
    "#epoch_wise_loss.append(epoch_loss)\n",
    "#epoch_wise_accu.append(epoch_accu)\n",
    "''' \n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model_loss vs epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epochs')\n",
    "s = '../working/epochwise_loss'\n",
    "plt.savefig(s)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('Model_Accuracy vs epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "s = '../working/epochwise_accuracy'\n",
    "plt.savefig(s)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "plt.plot(accu_hist)\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "s = '../working/accuracy_plot_' + str(epochs)\n",
    "plt.savefig(s)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "plt.plot(loss_hist)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "s = '../working/loss_plot_' + str(epochs)\n",
    "plt.savefig(s)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "model.save('../working/2d_4class_axis1.h5')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "surv-pred-evaluate (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
