{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shalabh147/Brain-Tumor-Segmentation-and-Survival-Prediction-using-Deep-Neural-Networks/blob/master/2d_4class_models/Axis%203/2d_4class_axis3train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "vSuAzM7OA-Iz"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras import metrics\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,Maximum\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D,MaxPooling3D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "# from medpy.io import load\n",
    "import numpy as np\n",
    "\n",
    "#import cv2\n",
    "import nibabel as nib\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "vSuAzM7OA-Iz"
   },
   "outputs": [],
   "source": [
    "def conv_block(input_mat,num_filters,kernel_size,batch_norm):\n",
    "  X = Conv2D(num_filters,kernel_size=(kernel_size,kernel_size),strides=(1,1),padding='same')(input_mat)\n",
    "  if batch_norm:\n",
    "    X = BatchNormalization()(X)\n",
    "  \n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  X = Conv2D(num_filters,kernel_size=(kernel_size,kernel_size),strides=(1,1),padding='same')(X)\n",
    "  if batch_norm:\n",
    "    X = BatchNormalization()(X)\n",
    "  \n",
    "  X = Activation('relu')(X)\n",
    "  \n",
    "  return X\n",
    "\n",
    "def Unet(input_img, n_filters = 16, dropout = 0.2, batch_norm = True):\n",
    "\n",
    "  c1 = conv_block(input_img,n_filters,3,batch_norm)\n",
    "  p1 = MaxPooling2D(pool_size=(2, 2), strides=2)(c1)\n",
    "  p1 = Dropout(dropout)(p1)\n",
    "  \n",
    "  c2 = conv_block(p1,n_filters*2,3,batch_norm);\n",
    "  p2 = MaxPooling2D(pool_size=(2,2) ,strides=2)(c2)\n",
    "  p2 = Dropout(dropout)(p2)\n",
    "\n",
    "  c3 = conv_block(p2,n_filters*4,3,batch_norm);\n",
    "  p3 = MaxPooling2D(pool_size=(2,2) ,strides=2)(c3)\n",
    "  p3 = Dropout(dropout)(p3)\n",
    "  \n",
    "  c4 = conv_block(p3,n_filters*8,3,batch_norm);\n",
    "  p4 = MaxPooling2D(pool_size=(2,2) ,strides=2)(c4)\n",
    "  p4 = Dropout(dropout)(p4)\n",
    "  \n",
    "  c5 = conv_block(p4,n_filters*16,3,batch_norm);\n",
    "\n",
    "  u6 = Conv2DTranspose(n_filters*8, (3,3), strides=(2, 2), padding='same')(c5);\n",
    "  u6 = concatenate([u6,c4]);\n",
    "  c6 = conv_block(u6,n_filters*8,3,batch_norm)\n",
    "  c6 = Dropout(dropout)(c6)\n",
    "  u7 = Conv2DTranspose(n_filters*4,(3,3),strides = (2,2) , padding= 'same')(c6);\n",
    "\n",
    "  u7 = concatenate([u7,c3]);\n",
    "  c7 = conv_block(u7,n_filters*4,3,batch_norm)\n",
    "  c7 = Dropout(dropout)(c7)\n",
    "  u8 = Conv2DTranspose(n_filters*2,(3,3),strides = (2,2) , padding='same')(c7);\n",
    "  u8 = concatenate([u8,c2]);\n",
    "\n",
    "  c8 = conv_block(u8,n_filters*2,3,batch_norm)\n",
    "  c8 = Dropout(dropout)(c8)\n",
    "  u9 = Conv2DTranspose(n_filters,(3,3),strides = (2,2) , padding='same')(c8);\n",
    "\n",
    "  u9 = concatenate([u9,c1]);\n",
    "\n",
    "  c9 = conv_block(u9,n_filters,3,batch_norm)\n",
    "  outputs = Conv2D(4, (1, 1), activation='softmax')(c9)\n",
    "\n",
    "  model = Model(inputs=input_img, outputs=outputs)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "vSuAzM7OA-Iz"
   },
   "outputs": [],
   "source": [
    "def standardize(image):\n",
    "\n",
    "  standardized_image = np.zeros(image.shape)\n",
    "\n",
    "  #\n",
    "  \n",
    "      # iterate over the `z` dimension\n",
    "  for z in range(image.shape[2]):\n",
    "      # get a slice of the image \n",
    "      # at channel c and z-th dimension `z`\n",
    "      image_slice = image[:,:,z]\n",
    "\n",
    "      # subtract the mean from image_slice\n",
    "      centered = image_slice - np.mean(image_slice)\n",
    "      \n",
    "      # divide by the standard deviation (only if it is different from zero)\n",
    "      if(np.std(centered)!=0):\n",
    "          centered = centered/np.std(centered) \n",
    "\n",
    "      # update  the slice of standardized image\n",
    "      # with the scaled centered and scaled image\n",
    "      standardized_image[:, :, z] = centered\n",
    "\n",
    "  ### END CODE HERE ###\n",
    "\n",
    "  return standardized_image\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "    \n",
    "    \"\"\"\n",
    "    axis = (0,1,2)\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "vSuAzM7OA-Iz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 240, 240, 4) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 240, 240, 32) 1184        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 240, 240, 32) 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 240, 240, 32) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 240, 240, 32) 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 240, 240, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 240, 240, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 120, 120, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 120, 120, 32) 0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 120, 120, 64) 18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 120, 120, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 120, 120, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 120, 120, 64) 36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 120, 120, 64) 256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 120, 120, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 60, 60, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 60, 60, 64)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 60, 60, 128)  73856       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 60, 60, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 60, 60, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 60, 60, 128)  147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 60, 60, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 60, 60, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 30, 30, 128)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 30, 30, 128)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 30, 30, 256)  295168      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 30, 30, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 30, 30, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 30, 30, 256)  590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 30, 30, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 30, 30, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 15, 15, 256)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 15, 15, 256)  0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 15, 15, 512)  1180160     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 15, 15, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 15, 15, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 15, 15, 512)  2359808     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 15, 15, 512)  2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 15, 15, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 30, 30, 256)  1179904     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 30, 30, 512)  0           conv2d_transpose[0][0]           \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 30, 30, 256)  1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 30, 30, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 30, 30, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 30, 30, 256)  590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 30, 30, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 30, 30, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 30, 30, 256)  0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 60, 60, 128)  295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 60, 60, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 60, 60, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 60, 60, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 60, 60, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 60, 60, 128)  147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 60, 60, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 60, 60, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 60, 60, 128)  0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 120, 120, 64) 73792       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 120, 120, 128 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 120, 120, 64) 73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 120, 120, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 120, 120, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 120, 120, 64) 36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 120, 120, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 120, 120, 64) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 120, 120, 64) 0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 240, 240, 32) 18464       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 240, 240, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 240, 240, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 240, 240, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 240, 240, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 240, 240, 32) 9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 240, 240, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 240, 240, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 240, 240, 4)  132         activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 8,642,660\n",
      "Trainable params: 8,636,772\n",
      "Non-trainable params: 5,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input((240,240,4))\n",
    "model = Unet(input_img,32,0.14,True)\n",
    "learning_rate = 0.00095\n",
    "#epochs = 5000\n",
    "decay_rate = 0.0000002\n",
    "model.compile(optimizer=Adam(lr=learning_rate, decay = decay_rate), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "vSuAzM7OA-Iz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "Brats18_2013_10_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-ce04e9273505>:40: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  image_data = img.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered modality\n",
      "Entered ground truth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-ce04e9273505>:35: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  image_data2 = img.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered modality\n",
      "Entered modality\n",
      "Entered modality\n",
      "(240, 240, 155, 4)\n",
      "(240, 240, 155)\n",
      "(44, 240, 240, 4)\n",
      "(44, 240, 240)\n",
      "(44, 240, 240)\n",
      "Number of classes [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass classes=[0 1 2 3], y=[0 0 0 ... 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights [ 0.25757919 25.37343318 28.65801257 23.04502801]\n"
     ]
    }
   ],
   "source": [
    "path = '/home/vivek/Desktop/BTP_2020/Segmentation/dataset/MICCAI_BraTS_2018_Data_Training/HGG'\n",
    "all_images = os.listdir(path)\n",
    "#print(len(all_images))\n",
    "all_images.sort()\n",
    "data = np.zeros((240,240,155,4))\n",
    "image_data2=np.zeros((240,240,155))\n",
    "loss_hist = []\n",
    "accu_hist = []\n",
    "epoch_wise_loss = []\n",
    "epoch_wise_accu = []\n",
    "for epochs in range(4):\n",
    "  epoch_loss = 0\n",
    "  epoch_accu = 0\n",
    "  for image_num in range(100):\n",
    "    x_to = []\n",
    "    y_to = []\n",
    "    print(epochs)\n",
    "    print(image_num)\n",
    "\n",
    "# data preprocessing starts here\n",
    "\n",
    "    x = all_images[image_num]\n",
    "    print(x)\n",
    "    folder_path = path + '/' + x;\n",
    "    modalities = os.listdir(folder_path)\n",
    "    modalities.sort()\n",
    "    #data = []\n",
    "    w = 0\n",
    "    for j in range(len(modalities)):\n",
    "      #print(modalities[j])\n",
    "      \n",
    "      image_path = folder_path + '/' + modalities[j]\n",
    "      if not(image_path.find('seg.nii') == -1):\n",
    "        img = nib.load(image_path);\n",
    "        image_data2 = img.get_data()\n",
    "        image_data2 = np.asarray(image_data2)\n",
    "        print(\"Entered ground truth\")\n",
    "      else:\n",
    "        img = nib.load(image_path);\n",
    "        image_data = img.get_data()\n",
    "        image_data = np.asarray(image_data)\n",
    "        image_data = standardize(image_data)\n",
    "        data[:,:,:,w] = image_data\n",
    "        print(\"Entered modality\")\n",
    "        w = w+1\n",
    "      \n",
    "    print(data.shape)\n",
    "    print(image_data2.shape)  \n",
    "    \n",
    "    '''\n",
    "    reshaped_data=data[56:184,75:203,13:141,:]\n",
    "    reshaped_data=reshaped_data.reshape(1,128,128,128,4)\n",
    "    reshaped_image_data2=image_data2[56:184,75:203,13:141]\n",
    "\n",
    "        \n",
    "    reshaped_image_data2=reshaped_image_data2.reshape(1,128,128,128)\n",
    "    reshaped_image_data2[reshaped_image_data2==4] = 3\n",
    "    hello = reshaped_image_data2.flatten()\n",
    "    #y_to = keras.utils.to_categorical(y_to,num_classes=2)\n",
    "    print(reshaped_image_data2.shape)\n",
    "    #print(hello[hello==3].shape)\n",
    "    print(\"Number of classes\",np.unique(hello))\n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(hello),hello)\n",
    "    print(class_weights)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    for slice_no in range(0,155):\n",
    "        a = slice_no\n",
    "        X = data[:,:,slice_no,:]\n",
    "\n",
    "        Y = image_data2[:,:,slice_no]\n",
    "        # imgplot = plt.imshow(X[:,:,2])\n",
    "        # plt.show(block=False)\n",
    "        # plt.pause(0.3)\n",
    "        # plt.close()\n",
    "\n",
    "        # imgplot = plt.imshow(Y)\n",
    "        # plt.show(block=False)\n",
    "        # plt.pause(0.3)\n",
    "        # plt.close()\n",
    "\n",
    "        if(X.any()!=0 and Y.any()!=0 and len(np.unique(Y)) == 4):\n",
    "          #print(slice_no)\n",
    "          x_to.append(X)\n",
    "          y_to.append(Y)\n",
    "          if len(y_to)>=44:\n",
    "                break;\n",
    "\n",
    "        #reshaped_image_data2 = to_categorical(reshaped_image_data2, num_classes = 4)\n",
    "\n",
    "        #print(reshaped_data.shape)\n",
    "        #print(reshaped_image_data2.shape)\n",
    "        #print(type(reshaped_data))\n",
    "\n",
    "    x_to = np.asarray(x_to)\n",
    "    y_to = np.asarray(y_to)\n",
    "    print(x_to.shape)\n",
    "    print(y_to.shape)\n",
    "\n",
    "  \n",
    "    y_to[y_to==4] = 3         \n",
    "    #y_to = one_hot_encode(y_to)\n",
    "    #y_to[y_to==2] = 1\n",
    "    #y_to[y_to==1] = 1\n",
    "    #y_to[y_to==0] = 0\n",
    "    print(y_to.shape)\n",
    "    \n",
    "    \n",
    "    from sklearn.utils import shuffle\n",
    "    x_to,y_to = shuffle(x_to,y_to)\n",
    "    \n",
    "    hello = y_to.flatten()\n",
    "    #print(hello[hello==3].shape)\n",
    "    print(\"Number of classes\",np.unique(hello))\n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(hello),hello)\n",
    "  \n",
    "    #class_weights.insert(3,0)\n",
    "    print(\"class_weights\",class_weights)\n",
    "\n",
    "\n",
    "    y_to = keras.utils.to_categorical(y_to,num_classes=4)\n",
    "    history = model.fit(x=x_to,y=y_to, epochs = 1 , batch_size = 44)\n",
    "    print(history.history['loss'])\n",
    "    epoch_loss += history.history['loss'][0]\n",
    "    epoch_accu += history.history['dice_coef'][0]    \n",
    "    loss_hist.append(history.history['loss'])\n",
    "    accu_hist.append(history.history['dice_coef'])\n",
    "  \n",
    "  model.save('/home/vivek/Desktop/BTP_2020/Segmentation/working/2d_4class_axis3.h5')\n",
    "  epoch_loss = epoch_loss/180\n",
    "  epoch_accu = epoch_accu/180\n",
    "\n",
    "  epoch_wise_loss.append(epoch_loss)\n",
    "  epoch_wise_accu.append(epoch_accu)\n",
    "  \n",
    "  plt.plot(epoch_wise_loss)\n",
    "  plt.title('Model_loss vs epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('epochs')\n",
    "  s = '../working/epochwise_loss_' + str(epochs)\n",
    "  plt.savefig(s)\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "  \n",
    "  plt.plot(epoch_wise_accu)\n",
    "  plt.title('Model_Accuracy vs epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('epochs')\n",
    "  s = '../working/epochwise_accu_' + str(epochs)\n",
    "  plt.savefig(s)\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "    \n",
    "  plt.plot(accu_hist)\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  s = '../working/accuracy_plot_' + str(epochs)\n",
    "  plt.savefig(s)\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "    \n",
    "  plt.plot(loss_hist)\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  s = '../working/loss_plot_' + str(epochs)\n",
    "  plt.savefig(s)\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "\n",
    "model.save('../working/2d_4class_axis3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "uRmDn3FQA-I5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "2d-4class-axis3train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
