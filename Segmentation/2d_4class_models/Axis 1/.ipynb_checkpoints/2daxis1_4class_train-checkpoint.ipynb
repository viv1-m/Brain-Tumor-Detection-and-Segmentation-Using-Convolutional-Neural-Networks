{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/shalabh147/Brain-Tumor-Segmentation-and-Survival-Prediction-using-Deep-Neural-Networks/blob/master/2daxis1_4class_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "3rrcXPO90JNM"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras import metrics\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout,Maximum\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose,Conv3D,Conv3DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D,MaxPooling3D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import os\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "# from medpy.io import load\n",
    "import numpy as np\n",
    "\n",
    "#import cv2\n",
    "import nibabel as nib\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "3rrcXPO90JNM"
   },
   "outputs": [],
   "source": [
    "def conv_block(input_mat,num_filters,kernel_size,batch_norm):\n",
    "  X = Conv2D(num_filters,kernel_size=(kernel_size,kernel_size),strides=(1,1),padding='same')(input_mat)\n",
    "  if batch_norm:\n",
    "    X = BatchNormalization()(X)\n",
    " \n",
    "  X = Activation('relu')(X)\n",
    "\n",
    "  X = Conv2D(num_filters,kernel_size=(kernel_size,kernel_size),strides=(1,1),padding='same')(X)\n",
    "  if batch_norm:\n",
    "    X = BatchNormalization()(X)\n",
    " \n",
    "  X = Activation('relu')(X)\n",
    " \n",
    "  return X\n",
    "\n",
    "def Unet_with_slice(input_img, n_filters = 16 , dropout = 0.3 , batch_norm = True):\n",
    "  c1 = Conv2D(16,kernel_size = (1,6) , strides = (1,1) ,padding = 'valid')(input_img)\n",
    "  if batch_norm:\n",
    "    c1 = BatchNormalization()(c1)\n",
    "  #print(c1.shape)\n",
    "  c1 = Activation('relu')(c1)\n",
    "\n",
    "  c1 = Conv2D(n_filters,kernel_size=(3,3),strides=(1,1),padding='same')(c1)\n",
    "  if batch_norm:\n",
    "    c1 = BatchNormalization()(c1)\n",
    " \n",
    "  c1 = Activation('relu')(c1)\n",
    "\n",
    "  p1 = MaxPooling2D(pool_size = (2,2) , strides = 2)(c1)\n",
    "  p1 = Dropout(dropout)(p1)\n",
    "\n",
    "  #print(p1.shape)\n",
    "  c2 = conv_block(p1 , n_filters*2,3,batch_norm)\n",
    "  p2 = MaxPooling2D(pool_size=(3,3), strides=3)(c2)\n",
    "  p2 = Dropout(dropout)(p2)\n",
    "  #print(p2.shape)\n",
    "\n",
    "  c3 = conv_block(p2, n_filters*4,3,batch_norm)\n",
    "  #print(c3.shape)\n",
    "  p3 = MaxPooling2D(pool_size = (2,1) , strides = (2,1))(c3)\n",
    "  p3 = Dropout(dropout)(p3)\n",
    "  #print(p3.shape)\n",
    "\n",
    "  c4 = conv_block(p3, n_filters*8,3,batch_norm)\n",
    "  p4 = MaxPooling2D(pool_size = (4,4) , strides = (4,5))(c4)\n",
    "  p4 = Dropout(dropout)(p4)\n",
    "\n",
    "  c5 = conv_block(p4,n_filters*16,3,batch_norm)\n",
    "\n",
    "  u6 = Conv2DTranspose(n_filters*8,kernel_size = (4,4) , strides = (4,5) , padding = 'same')(c5)\n",
    "  u6 = concatenate([u6,c4])\n",
    "  c6 = conv_block(u6,n_filters*8,3,batch_norm)\n",
    "  c6 = Dropout(dropout)(c6)\n",
    "\n",
    "  u7 = Conv2DTranspose(n_filters*4,kernel_size = (3,3) , strides = (2,1) , padding = 'same')(c6)\n",
    "  u7 = concatenate([u7,c3])\n",
    "  c7 = conv_block(u7,n_filters*4,3,batch_norm)\n",
    "  c7 = Dropout(dropout)(c7)\n",
    "\n",
    "  u8 = Conv2DTranspose(n_filters*2,kernel_size = (3,3) , strides = (3,3) , padding = 'same')(c7)\n",
    "  u8 = concatenate([u8,c2])\n",
    "  c8 = conv_block(u8,n_filters*2,3,batch_norm)\n",
    "  c8 = Dropout(dropout)(c8)\n",
    "\n",
    "  u9 = Conv2DTranspose(n_filters,kernel_size = (3,3) , strides = (2,2) , padding = 'same')(c8)\n",
    "  u9 = concatenate([u9,c1])\n",
    "  c9 = conv_block(u9,n_filters,3,batch_norm)\n",
    "  c9 = Dropout(dropout)(c9)\n",
    "\n",
    "  c10 = Conv2DTranspose(n_filters, kernel_size = (1,6) , strides = (1,1), padding = 'valid')(c9)\n",
    "\n",
    "  outputs = Conv2D(4, kernel_size = (1,1), activation = 'softmax')(c10)\n",
    "\n",
    "  model = Model(inputs = input_img , outputs = outputs)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "3rrcXPO90JNM"
   },
   "outputs": [],
   "source": [
    "def standardize(image):\n",
    "\n",
    "  standardized_image = np.zeros(image.shape)\n",
    "\n",
    "  #\n",
    " \n",
    "      # iterate over the `z` dimension\n",
    "  for z in range(image.shape[2]):\n",
    "      # get a slice of the image\n",
    "      # at channel c and z-th dimension `z`\n",
    "      image_slice = image[:,:,z]\n",
    "\n",
    "      # subtract the mean from image_slice\n",
    "      centered = image_slice - np.mean(image_slice)\n",
    "     \n",
    "      # divide by the standard deviation (only if it is different from zero)\n",
    "      if(np.std(centered)!=0):\n",
    "          centered = centered/np.std(centered)\n",
    "\n",
    "      # update  the slice of standardized image\n",
    "      # with the scaled centered and scaled image\n",
    "      standardized_image[:, :, z] = centered\n",
    "\n",
    "  ### END CODE HERE ###\n",
    "\n",
    "  return standardized_image\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred, epsilon=0.00001):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    ref: https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "   \n",
    "    \"\"\"\n",
    "    axis = (0,1,2)\n",
    "    dice_numerator = 2. * K.sum(y_true * y_pred, axis=axis) + epsilon\n",
    "    dice_denominator = K.sum(y_true*y_true, axis=axis) + K.sum(y_pred*y_pred, axis=axis) + epsilon\n",
    "    return K.mean((dice_numerator)/(dice_denominator))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "3rrcXPO90JNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 240, 155, 4) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 240, 150, 16) 400         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 240, 150, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 240, 150, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 240, 150, 32) 4640        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 240, 150, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 240, 150, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 120, 75, 32)  0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 120, 75, 32)  0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 120, 75, 64)  18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 120, 75, 64)  256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 120, 75, 64)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 120, 75, 64)  36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 120, 75, 64)  256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 120, 75, 64)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 40, 25, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 40, 25, 64)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 40, 25, 128)  73856       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 40, 25, 128)  512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 40, 25, 128)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 40, 25, 128)  147584      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 40, 25, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 40, 25, 128)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 20, 25, 128)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 20, 25, 128)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 20, 25, 256)  295168      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 20, 25, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 20, 25, 256)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 20, 25, 256)  590080      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 20, 25, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 20, 25, 256)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 256)    0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 5, 5, 256)    0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 5, 5, 512)    1180160     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 5, 5, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5, 5, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 5, 5, 512)    2359808     activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 5, 5, 512)    2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 5, 5, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 20, 25, 256)  2097408     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20, 25, 512)  0           conv2d_transpose[0][0]           \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 20, 25, 256)  1179904     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 20, 25, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 20, 25, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 20, 25, 256)  590080      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 20, 25, 256)  1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 20, 25, 256)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 20, 25, 256)  0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 40, 25, 128)  295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 40, 25, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 40, 25, 128)  295040      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 40, 25, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 40, 25, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 40, 25, 128)  147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 40, 25, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 40, 25, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 40, 25, 128)  0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 120, 75, 64)  73792       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 120, 75, 128) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 120, 75, 64)  73792       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 120, 75, 64)  256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 120, 75, 64)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 120, 75, 64)  36928       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 120, 75, 64)  256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 120, 75, 64)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 120, 75, 64)  0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 240, 150, 32) 18464       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 240, 150, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 240, 150, 32) 18464       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 240, 150, 32) 128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 240, 150, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 240, 150, 32) 9248        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 240, 150, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 240, 150, 32) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 240, 150, 32) 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 240, 155, 32) 6176        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 240, 155, 4)  132         conv2d_transpose_4[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 9,560,884\n",
      "Trainable params: 9,555,028\n",
      "Non-trainable params: 5,856\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = Input((240,155,4))\n",
    "model = Unet_with_slice(input_img,32,0.15,True)\n",
    "learning_rate = 0.00095\n",
    "#epochs = 5000\n",
    "decay_rate = 0.0000002\n",
    "model.compile(optimizer=Adam(lr=learning_rate, decay = decay_rate), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "3rrcXPO90JNM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "Brats18_2013_10_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-623aac68311d>:40: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  image_data = img.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered modality\n",
      "Entered ground truth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-623aac68311d>:35: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "  image_data2 = img.get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered modality\n",
      "Entered modality\n",
      "Entered modality\n",
      "(240, 240, 155, 4)\n",
      "(240, 240, 155)\n",
      "(43, 240, 155, 4)\n",
      "(43, 240, 155)\n",
      "(43, 240, 155)\n",
      "Number of classes [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vivek/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass classes=[0 1 2 3], y=[0 0 0 ... 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weights [ 0.26803434 14.70815403  8.16906012 12.70128633]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-623aac68311d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0my_to\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1048\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1051\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m       \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "path = '/home/vivek/Desktop/BTP_2020/Segmentation/dataset/MICCAI_BraTS_2018_Data_Training/HGG'\n",
    "all_images = os.listdir(path)\n",
    "#print(len(all_images))\n",
    "all_images.sort()\n",
    "data = np.zeros((240,240,155,4))\n",
    "image_data2=np.zeros((240,240,155))\n",
    "loss_hist = []\n",
    "accu_hist = []\n",
    "epoch_wise_loss = []\n",
    "epoch_wise_accu = []\n",
    "for epochs in range(45):\n",
    "  epoch_loss = 0\n",
    "  epoch_accu = 0\n",
    "  for image_num in range(180):\n",
    "    x_to = []\n",
    "    y_to = []\n",
    "    print(epochs)\n",
    "    print(image_num)\n",
    "\n",
    "# data preprocessing starts here\n",
    "\n",
    "    x = all_images[image_num]\n",
    "    print(x)\n",
    "    folder_path = path + '/' + x;\n",
    "    modalities = os.listdir(folder_path)\n",
    "    modalities.sort()\n",
    "    #data = []\n",
    "    w = 0\n",
    "    for j in range(len(modalities)):\n",
    "      #print(modalities[j])\n",
    "     \n",
    "      image_path = folder_path + '/' + modalities[j]\n",
    "      if not(image_path.find('seg.nii') == -1):\n",
    "        img = nib.load(image_path);\n",
    "        image_data2 = img.get_data()\n",
    "        image_data2 = np.asarray(image_data2)\n",
    "        print(\"Entered ground truth\")\n",
    "      else:\n",
    "        img = nib.load(image_path);\n",
    "        image_data = img.get_data()\n",
    "        image_data = np.asarray(image_data)\n",
    "        image_data = standardize(image_data)\n",
    "        data[:,:,:,w] = image_data\n",
    "        print(\"Entered modality\")\n",
    "        w = w+1\n",
    "     \n",
    "    print(data.shape)\n",
    "    print(image_data2.shape)  \n",
    "   \n",
    "    '''\n",
    "    reshaped_data=data[56:184,75:203,13:141,:]\n",
    "    reshaped_data=reshaped_data.reshape(1,128,128,128,4)\n",
    "    reshaped_image_data2=image_data2[56:184,75:203,13:141]\n",
    "\n",
    "       \n",
    "    reshaped_image_data2=reshaped_image_data2.reshape(1,128,128,128)\n",
    "    reshaped_image_data2[reshaped_image_data2==4] = 3\n",
    "    hello = reshaped_image_data2.flatten()\n",
    "    #y_to = keras.utils.to_categorical(y_to,num_classes=2)\n",
    "    print(reshaped_image_data2.shape)\n",
    "    #print(hello[hello==3].shape)\n",
    "    print(\"Number of classes\",np.unique(hello))\n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(hello),hello)\n",
    "    print(class_weights)\n",
    "   \n",
    "   \n",
    "    '''\n",
    "   \n",
    "   \n",
    "    for slice_no in range(0,240):\n",
    "        a = slice_no\n",
    "        X = data[slice_no,:,:,:]\n",
    "\n",
    "        Y = image_data2[slice_no,:,:]\n",
    "        # imgplot = plt.imshow(X[:,:,2])\n",
    "        # plt.show(block=False)\n",
    "        # plt.pause(0.3)\n",
    "        # plt.close()\n",
    "\n",
    "        # imgplot = plt.imshow(Y)\n",
    "        # plt.show(block=False)\n",
    "        # plt.pause(0.3)\n",
    "        # plt.close()\n",
    "\n",
    "        if(X.any()!=0 and Y.any()!=0 and len(np.unique(Y)) == 4):\n",
    "          #print(slice_no)\n",
    "          x_to.append(X)\n",
    "          y_to.append(Y)\n",
    "          if len(y_to)>=50:\n",
    "                break;\n",
    "\n",
    "        #reshaped_image_data2 = to_categorical(reshaped_image_data2, num_classes = 4)\n",
    "\n",
    "        #print(reshaped_data.shape)\n",
    "        #print(reshaped_image_data2.shape)\n",
    "        #print(type(reshaped_data))\n",
    "\n",
    "    x_to = np.asarray(x_to)\n",
    "    y_to = np.asarray(y_to)\n",
    "    print(x_to.shape)\n",
    "    print(y_to.shape)\n",
    "\n",
    " \n",
    "    y_to[y_to==4] = 3        \n",
    "    #y_to = one_hot_encode(y_to)\n",
    "    #y_to[y_to==2] = 1\n",
    "    #y_to[y_to==1] = 1\n",
    "    #y_to[y_to==0] = 0\n",
    "    print(y_to.shape)\n",
    "   \n",
    "   \n",
    "    from sklearn.utils import shuffle\n",
    "    x_to,y_to = shuffle(x_to,y_to)\n",
    "   \n",
    "    hello = y_to.flatten()\n",
    "    #print(hello[hello==3].shape)\n",
    "    print(\"Number of classes\",np.unique(hello))\n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(hello),hello)\n",
    "    class_weights = {i : class_weight[i] for i in range(4)}\n",
    " \n",
    "    #class_weights.insert(3,0)\n",
    "    print(\"class_weights\",class_weights)\n",
    "\n",
    "\n",
    "    y_to = keras.utils.to_categorical(y_to,num_classes=4)\n",
    "    history = model.fit(x=x_to,y=y_to, epochs = 1 , batch_size = 50 ,class_weight = class_weights)\n",
    "    print(history.history['loss'])\n",
    "    epoch_loss += history.history['loss'][0]\n",
    "    epoch_accu += history.history['dice_coef'][0]\n",
    "   \n",
    "    loss_hist.append(history.history['loss'])\n",
    "    accu_hist.append(history.history['dice_coef'])\n",
    " \n",
    "  model.save('../working/2d_4class_axis1.h5')\n",
    "  epoch_loss = epoch_loss/180\n",
    "  epoch_accu = epoch_accu/180\n",
    "\n",
    "  epoch_wise_loss.append(epoch_loss)\n",
    "  epoch_wise_accu.append(epoch_accu)\n",
    " \n",
    "  plt.plot(epoch_wise_loss)\n",
    "  plt.title('Model_loss vs epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('epochs')\n",
    "  s = '../working/epochwise_loss_' + str(epochs)\n",
    "  plt.savefig(s)\n",
    "  plt.show()\n",
    "  plt.close()\n",
    " \n",
    "  plt.plot(epoch_wise_accu)\n",
    "  plt.title('Model_Accuracy vs epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('epochs')\n",
    "  s = '../working/epochwise_accu_' + str(epochs)\n",
    "  plt.savefig(s)\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "   \n",
    "  plt.plot(accu_hist)\n",
    "  plt.title('model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  s = '../working/accuracy_plot_' + str(epochs)\n",
    "  plt.savefig(s)\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "   \n",
    "  plt.plot(loss_hist)\n",
    "  plt.title('model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('epoch')\n",
    "  s = '../working/loss_plot_' + str(epochs)\n",
    "  plt.savefig(s)\n",
    "  plt.show()\n",
    "  plt.close()\n",
    "\n",
    "model.save('../working/2d_4class_axis1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "-2Pupv3n0JNg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "2daxis1_4class_train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
