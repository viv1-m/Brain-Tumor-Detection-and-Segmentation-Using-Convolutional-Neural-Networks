{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from os import listdir\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import Data_Augmentation\n",
    "import Data_Preprocessing\n",
    "import Data_Visualization\n",
    "import model_architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y148.JPG\n",
      "Y29.jpg\n",
      "Y160.JPG\n",
      "Y39.jpg\n",
      "Y10.jpg\n",
      "Y79.jpg\n",
      "Y14.jpg\n",
      "Y49.JPG\n",
      "Y253.JPG\n",
      "Y31.jpg\n",
      "Y34.jpg\n",
      "Y109.JPG\n",
      "Y62.jpg\n",
      "Y181.jpg\n",
      "Y99.JPG\n",
      "Y156.JPG\n",
      "Y44.JPG\n",
      "Y6.jpg\n",
      "Y3.jpg\n",
      "Y102.jpg\n",
      "Y106.jpg\n",
      "Y188.jpg\n",
      "Y168.jpg\n",
      "Y22.jpg\n",
      "Y98.JPG\n",
      "Y161.JPG\n",
      "Y40.JPG\n",
      "Y45.JPG\n",
      "Y182.JPG\n",
      "Y1.jpg\n",
      "Y257.jpg\n",
      "Y81.jpg\n",
      "Y60.jpg\n",
      "Y77.jpg\n",
      "Y153.jpg\n",
      "Y24.jpg\n",
      "Y163.JPG\n",
      "Y32.jpg\n",
      "Y7.jpg\n",
      "Y33.jpg\n",
      "Y194.jpg\n",
      "Y65.JPG\n",
      "Y96.jpg\n",
      "Y252.jpg\n",
      "Y187.jpg\n",
      "Y259.JPG\n",
      "Y70.jpg\n",
      "Y116.JPG\n",
      "Y86.JPG\n",
      "Y91.jpg\n",
      "Y78.jpg\n",
      "Y107.jpg\n",
      "Y66.JPG\n",
      "Y16.JPG\n",
      "Y38.jpg\n",
      "Y61.jpg\n",
      "Y158.JPG\n",
      "Y180.jpg\n",
      "Y243.JPG\n",
      "Y19.JPG\n",
      "Y247.JPG\n",
      "Y251.JPG\n",
      "Y69.jpg\n",
      "Y101.jpg\n",
      "Y146.JPG\n",
      "Y67.JPG\n",
      "Y2.jpg\n",
      "Y100.JPG\n",
      "Y246.JPG\n",
      "Y18.JPG\n",
      "Y53.jpg\n",
      "Y105.jpg\n",
      "Y157.JPG\n",
      "Y90.jpg\n",
      "Y13.jpg\n",
      "Y162.jpg\n",
      "Y169.jpg\n",
      "Y164.JPG\n",
      "Y103.jpg\n",
      "Y8.jpg\n",
      "Y159.JPG\n",
      "Y114.JPG\n",
      "Y258.JPG\n",
      "Y249.JPG\n",
      "Y4.jpg\n",
      "Y155.JPG\n",
      "Y147.JPG\n",
      "Y85.JPG\n",
      "Y165.JPG\n",
      "Y192.JPG\n",
      "Y112.JPG\n",
      "Y245.jpg\n",
      "Y21.jpg\n",
      "Y59.JPG\n",
      "Y92.png\n",
      "Y254.jpg\n",
      "Y170.JPG\n",
      "Y82.jpg\n",
      "Y41.jpg\n",
      "Y15.jpg\n",
      "Y255.JPG\n",
      "Y55.jpg\n",
      "Y58.JPG\n",
      "Y186.jpg\n",
      "Y30.jpg\n",
      "Y113.JPG\n",
      "Y35.jpg\n",
      "Y193.JPG\n",
      "Y195.JPG\n",
      "Y37.jpg\n",
      "Y248.JPG\n",
      "Y117.JPG\n",
      "Y20.jpg\n",
      "Y244.JPG\n",
      "Y71.JPG\n",
      "Y25.jpg\n",
      "Y89.JPG\n",
      "Y256.JPG\n",
      "Y166.JPG\n",
      "Y183.jpg\n",
      "Y108.jpg\n",
      "Y52.jpg\n",
      "Y23.JPG\n",
      "Y167.JPG\n",
      "Y97.JPG\n",
      "Y46.jpg\n",
      "Y54.jpg\n",
      "Y27.jpg\n",
      "Y17.jpg\n",
      "Y74.jpg\n",
      "Y92.jpg\n",
      "Y26.jpg\n",
      "Y185.jpg\n",
      "Y12.jpg\n",
      "Y115.JPG\n",
      "Y120.JPG\n",
      "Y36.JPG\n",
      "Y51.jpg\n",
      "Y95.jpg\n",
      "Y242.JPG\n",
      "Y73.jpg\n",
      "Y111.JPG\n",
      "Y11.jpg\n",
      "Y154.jpg\n",
      "Y47.JPG\n",
      "Y28.jpg\n",
      "Y56.jpg\n",
      "Y50.JPG\n",
      "Y42.jpg\n",
      "Y75.JPG\n",
      "Y76.jpg\n",
      "Y104.jpg\n",
      "Y184.JPG\n",
      "Y9.jpg\n",
      "Y250.jpg\n",
      "N11.jpg\n",
      "13 no.jpg\n",
      "19 no.jpg\n",
      "5 no.jpg\n",
      "42 no.jpg\n",
      "18 no.jpg\n",
      "N21.jpg\n",
      "no 8.jpg\n",
      "50 no.jpg\n",
      "No22.jpg\n",
      "no 100.jpg\n",
      "N5.jpg\n",
      "11 no.jpg\n",
      "no 7.jpeg\n",
      "37 no.jpg\n",
      "7 no.jpg\n",
      "48 no.jpeg\n",
      "21 no.jpg\n",
      "40 no.jpg\n",
      "N19.JPG\n",
      "no 96.jpg\n",
      "28 no.jpg\n",
      "45 no.jpg\n",
      "no 1.jpg\n",
      "46 no.jpg\n",
      "no 3.jpg\n",
      "34 no.jpg\n",
      "27 no.jpg\n",
      "24 no.jpg\n",
      "No14.jpg\n",
      "22 no.jpg\n",
      "N26.JPG\n",
      "no 2.jpg\n",
      "41 no.jpg\n",
      "no 90.jpg\n",
      "No19.jpg\n",
      "25 no.jpg\n",
      "no 89.jpg\n",
      "N6.jpg\n",
      "N22.JPG\n",
      "6 no.jpg\n",
      "no 98.jpg\n",
      "17 no.jpg\n",
      "no 94.jpg\n",
      "N2.JPG\n",
      "43 no.jpg\n",
      "N3.jpg\n",
      "4 no.jpg\n",
      "No21.jpg\n",
      "36 no.jpg\n",
      "No16.jpg\n",
      "no 9.png\n",
      "N16.jpg\n",
      "no 92.jpg\n",
      "N1.JPG\n",
      "38 no.jpg\n",
      "No12.jpg\n",
      "no 97.jpg\n",
      "no 6.jpg\n",
      "9 no.jpg\n",
      "no.jpg\n",
      "3 no.jpg\n",
      "49 no.jpg\n",
      "N17.jpg\n",
      "no 4.jpg\n",
      "44no.jpg\n",
      "29 no.jpg\n",
      "31 no.jpg\n",
      "39 no.jpg\n",
      "No20.jpg\n",
      "10 no.jpg\n",
      "no 5.jpeg\n",
      "23 no.jpg\n",
      "20 no.jpg\n",
      "2 no.jpeg\n",
      "no 95.jpg\n",
      "14 no.jpg\n",
      "33 no.jpg\n",
      "35 no.jpg\n",
      "N15.jpg\n",
      "26 no.jpg\n",
      "no 91.jpeg\n",
      "N20.JPG\n",
      "no 923.jpg\n",
      "47 no.jpg\n",
      "no 99.jpg\n",
      "No17.jpg\n",
      "8 no.jpg\n",
      "32 no.jpg\n",
      "No15.jpg\n",
      "30 no.jpg\n",
      "no 10.jpg\n",
      "No18.jpg\n",
      "15 no.jpg\n",
      "No11.jpg\n",
      "1 no.jpeg\n",
      "No13.jpg\n",
      "12 no.jpg\n"
     ]
    }
   ],
   "source": [
    "augmented_path = 'augmented_data/'\n",
    "\n",
    "yes_path = 'data/yes'\n",
    "no_path = 'data/no'\n",
    "\n",
    "Data_Augmentation.augment_data(file_dir=yes_path, n_generated_samples=6, save_to_dir=augmented_path+'aug_yes')\n",
    "Data_Augmentation.augment_data(file_dir=no_path, n_generated_samples=9, save_to_dir=augmented_path+'aug_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2064\n",
      "% of tumor cases     =  52.56782945736434\n",
      "% of non-tumor cases =  47.43217054263566\n"
     ]
    }
   ],
   "source": [
    "aug_yes_path = 'augmented_data/aug_yes'\n",
    "aug_no_path = 'augmented_data/aug_no'\n",
    "\n",
    "m_aug_yes = len(listdir(aug_yes_path))\n",
    "m_aug_no = len(listdir(aug_no_path))\n",
    "\n",
    "m_aug = m_aug_yes + m_aug_no\n",
    "\n",
    "print(m_aug)\n",
    "\n",
    "print(\"% of tumor cases     = \" , m_aug_yes*100/m_aug)\n",
    "print(\"% of non-tumor cases = \" , m_aug_no*100/m_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_yes = augmented_path + 'yes' \n",
    "augmented_no = augmented_path + 'no'\n",
    "\n",
    "IMG_WIDTH, IMG_HEIGHT = (240, 240)\n",
    "\n",
    "X, y = Data_Preprocessing.load_data([augmented_yes, augmented_no], (IMG_WIDTH, IMG_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Visualization.plot_sample_images(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2):\n",
    "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_architecture.build_model(IMG_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_name = f'brain_tumor_detection_cnn_{int(time.time())}'\n",
    "tensorboard = TensorBoard(log_dir=f'logs/{log_file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"cnn-parameters-improvement-{epoch:02d}-{val_acc:.2f}\"\n",
    "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=32, epochs=10, validation_data=(X_val, y_val), callbacks=[tensorboard, checkpoint])\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = (end_time - start_time)\n",
    "print(execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the model loss and accuracy on training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set loss and accuracy with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(filepath='models/cnn-parameters-improvement-23-0.91.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = best_model.evaluate(x=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Test Loss = {loss}\")\n",
    "print (f\"Test Accuracy = {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prob = best_model.predict(X_test)\n",
    "y_val_prob = best_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1score = model_architecture.compute_f1_score(y_test, y_test_prob)\n",
    "print(f\"F1 score: {f1score}\")\n",
    "\n",
    "f1score_val = model_architecture.compute_f1_score(y_val, y_val_prob)\n",
    "print(f\"F1 score: {f1score_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
